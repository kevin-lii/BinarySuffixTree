{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain-Machine Interface Spike Sorting with PCA\n",
    "\n",
    "### EE 16B: Designing Information Devices and Systems II, Adapted from Original SVD Lab "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Task 1: Two Neuron Spike Sorting](#task1)\n",
    "* [Task 2: Three Neuron Spike Sorting](#task2)\n",
    "* [Task 3: Determining Neurons](#task3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Two Neuron Spike Sorting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'spike_waveforms.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'spike_waveforms'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d49193cbf15d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m presorted = {k: v for k, v in scipy.io.loadmat('spike_waveforms').items() \\\n\u001b[0m\u001b[1;32m     11\u001b[0m              if k in ('sig118a_wf', 'sig118b_wf', 'sig118c_wf')}\n\u001b[1;32m     12\u001b[0m \u001b[0mpresorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpresorted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sig118a_wf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpresorted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sig118b_wf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpresorted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sig118c_wf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \"\"\"\n\u001b[1;32m    221\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reader needs file name or open file-like object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'spike_waveforms.mat'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# %matplotlib notebook\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.cluster\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Load data\n",
    "presorted = {k: v for k, v in scipy.io.loadmat('spike_waveforms').items() \\\n",
    "             if k in ('sig118a_wf', 'sig118b_wf', 'sig118c_wf')}\n",
    "presorted = [presorted['sig118a_wf'], presorted['sig118b_wf'], presorted['sig118c_wf']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _make_training_set(data):\n",
    "    \"\"\" Separate data set into 2 sets. \n",
    "    1/6 of the dataset is training set and the rest is test set\n",
    "    Parameter:\n",
    "        data: waveform data (width = number of samples per spike)\n",
    "    \"\"\"\n",
    "    n = data.shape[0]\n",
    "    idx_training = np.random.choice(n, n//6, replace=False)\n",
    "    training_set = data[idx_training]\n",
    "    test_set = [data[i] for i in range(n) if n not in idx_training]\n",
    "    return training_set, test_set\n",
    "\n",
    "# Create training and testing dataset\n",
    "two_neurons_training, two_neurons_test = _make_training_set(np.concatenate(presorted[1:]))\n",
    "three_neurons_training, three_neurons_test = _make_training_set(np.concatenate(presorted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot 100 random spikes\n",
    "for waveforms in three_neurons_training[:100]:\n",
    "    plt.plot(waveforms)\n",
    "plt.xlim((0,31))\n",
    "plt.title('100 random spikes')\n",
    "plt.figure()\n",
    "\n",
    "# Plot the 3 spike shapes based on the presorted data\n",
    "for waveforms in presorted:\n",
    "    plt.title(\"Waveforms of this spike shape\")\n",
    "    plt.plot(waveforms.T)\n",
    "    plt.figure()\n",
    "    plt.title(\"Average waveform of this spike shape\")\n",
    "    plt.plot(np.mean(waveforms, axis=0))\n",
    "    plt.figure()\n",
    "    \n",
    "plt.figure()   \n",
    "for waveforms in presorted:\n",
    "    plt.plot(np.mean(waveforms, axis=0))\n",
    "plt.xlim((0,31))\n",
    "plt.title('Averaged presorted 3 neuron spikes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be using <a href=\"http://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.svd.html\">np.linalg.svd</a> in your PCA function. Read the documentation for this function to figure out how to choose the principal components used as the basis for the lower dimensional space. (Note: in the docs, `a.H` means the congugate transpose of a)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def PCA_train(training_set, n_components):\n",
    "    \"\"\" Use np.linalg.svd to perform PCA\n",
    "    Parameters:\n",
    "        training_set: the data set to perform PCA on (MxN)\n",
    "        n_components: the dimensionality of the basis to return (i.e. number of neurons)\n",
    "    Returns: \n",
    "        The n_components principal components with highest significants and \n",
    "        the mean of each column of the original data\n",
    "    Hint: Subtract the mean of the data first so the average of each column is 0. The axis \n",
    "        parameter of np.mean is helpful here.\n",
    "    \"\"\"    \n",
    "    # YOUR CODE HERE #\n",
    "    # SOLN START #\n",
    "    mean = np.mean(training_set, axis=0)\n",
    "    training_set = training_set - mean\n",
    "    U, s, V = np.linalg.svd(training_set)\n",
    "    basis_components = V[:n_components]     # the larger components are given first\n",
    "    # SOLN END #\n",
    "    \n",
    "    return basis_components, mean\n",
    "\n",
    "def PCA_project(data, new_basis, mean):\n",
    "    \"\"\" Project the data set, adjusted by the mean, into the new basis vectors\n",
    "    Parameters:\n",
    "        data: data to project (MxN)\n",
    "        new_basis: new bases (KxN)\n",
    "        mean: mean of each timestamp from PCA (list of length N)\n",
    "    Returns: \n",
    "        Data projected onto new_basis (MxK)\n",
    "    Hint: Don't forget to adjust the data with the PCA training mean!\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE #\n",
    "    # SOLN START #\n",
    "    return np.dot(data-mean, new_basis.T)\n",
    "    # SOLN END #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Perform PCA and plot the first 2 principal components.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# BEGIN SOLN\n",
    "two_new_basis, two_mean = PCA_train(two_neurons_training, 2)\n",
    "# END SOLN\n",
    "\n",
    "# Plot the basis components\n",
    "for comp in two_new_basis:\n",
    "    plt.plot(comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_directions = np.random.randint(2, size=(2,32))\n",
    "\n",
    "two_projected = PCA_project(two_neurons_test, random_directions, two_mean)\n",
    "\n",
    "# Plot the projected neurons\n",
    "plt.figure()\n",
    "plt.scatter(*two_projected.T, s=1)\n",
    "plt.title('two_neurons_test')\n",
    "\n",
    "# Project the presorted data and plot it\n",
    "plt.figure()\n",
    "presorted_two_projected = [PCA_project(spikes, random_directions, two_mean) for spikes in presorted[1:]]\n",
    "colors = ['#0000ff', '#00ff00']\n",
    "for dat, color in zip(presorted_two_projected, colors):\n",
    "    plt.scatter(*dat.T, c=color, alpha=0.2,s=1)\n",
    "plt.title('Presorted data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Project the test data two_neurons_test to the basis you found earlier\n",
    "\n",
    "# YOUR CODE HERE #\n",
    "# SOLN START #\n",
    "two_projected = PCA_project(two_neurons_test, two_new_basis, two_mean)\n",
    "# SOLN END #\n",
    "\n",
    "# Plot the projected neurons\n",
    "plt.figure()\n",
    "plt.scatter(*two_projected.T,s=1)\n",
    "plt.title('two_neurons_test')\n",
    "\n",
    "# Project the presorted data and plot it\n",
    "plt.figure()\n",
    "presorted_two_projected = [PCA_project(spikes, two_new_basis, two_mean) for spikes in presorted[1:]]\n",
    "colors = ['#0000ff', '#00ff00']\n",
    "for dat, color in zip(presorted_two_projected, colors):\n",
    "    plt.scatter(*dat.T, c=color, s=1, alpha=0.2)\n",
    "plt.title('Presorted data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the first principal component separates the two neurons in the $x$-axis. Thus, technically we only need 1 principal component to separate the two neurons. This is because the algorithm maximizes the square of the dot product of each signal with the principal component, which results in a large positive dot product with 1 neuron and a large negative dot product with the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Three Neuron Spike Sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Repeat training with three neuron data, producing 3 principal components\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# BEGIN SOLN\n",
    "three_new_basis2, three_mean2 = PCA_train(three_neurons_training, 2)\n",
    "# END SOLN\n",
    "\n",
    "# Plot the resulting basis\n",
    "for comp in three_new_basis2:\n",
    "    plt.plot(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basis = three_new_basis2[0:2]\n",
    "three_projected_2 = PCA_project(three_neurons_test, basis , three_mean2)\n",
    "presorted_projected_2 = [PCA_project(spikes, basis, three_mean2) for spikes in presorted]\n",
    "\n",
    "\n",
    "# Plot the resulting projection\n",
    "plt.title(\"three_neurons_test projected to 2 principal components\")\n",
    "plt.scatter(three_projected_2.T[0], three_projected_2.T[1], s=1)\n",
    "plt.figure()\n",
    "\n",
    "plt.title(\"Presorted data projected to 2 principal components\")\n",
    "for p in presorted_projected_2:\n",
    "    plt.scatter(p.T[0], p.T[1], s=1, alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Repeat training with three neuron data, producing 3 principal components\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# BEGIN SOLN\n",
    "three_new_basis, three_mean = PCA_train(three_neurons_training, 3)\n",
    "# END SOLN\n",
    "\n",
    "# Plot the resulting basis\n",
    "for comp in three_new_basis:\n",
    "    plt.plot(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_3D(data, view_from_top=False):\n",
    "    \"\"\" Takes list of arrays (x, y, z) coordinate triples\n",
    "    One array of triples per color\n",
    "    \"\"\"\n",
    "    fig=plt.figure(figsize=(10,7))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    colors = ['#0000ff', '#00ff00', '#ff0000']\n",
    "    for dat, color in zip(data, colors):\n",
    "        Axes3D.scatter(ax, *dat.T, s=1, c=color, alpha=0.2)\n",
    "    if view_from_top:\n",
    "        ax.view_init(elev=90.,azim=0)                # Move perspective to view from top\n",
    "\n",
    "        \n",
    "# Classify the three_neurons_test data based on the basis computed above\n",
    "# YOUR CODE HERE #\n",
    "# BEGIN SOLN #\n",
    "three_projected = PCA_project(three_neurons_test, three_new_basis, three_mean)\n",
    "# END SOLN #\n",
    "\n",
    "# Plot the resulting projection\n",
    "plot_3D([three_projected], False)\n",
    "plt.title('three_neurons_test projected to 3 principal components')\n",
    "\n",
    "presorted_projected = [PCA_project(spikes, three_new_basis, three_mean) for spikes in presorted]\n",
    "plot_3D(np.array(presorted_projected), False)\n",
    "plt.title('Presorted data projected to 3 principal components')\n",
    "\n",
    "plot_3D(np.array(presorted_projected), True)\n",
    "plt.title('Top View: Presorted data projected to 3 principal components')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the second argument to the `plot_3D` function calls above to True to view the plots \"from the top\" (i.e. looking down the positive z axis).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Determining Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def which_neuron(data_point, centroid1, centroid2):\n",
    "    \"\"\" Determine which centroid is closest to the data point\n",
    "    Inputs:\n",
    "        data_point: 1x2 array containing x/y coordinates of data point\n",
    "        centroid1: 1x2 array containing x/y coordinates of centroid 1\n",
    "        centroid2: 1x2 array containing x/y coordinates of centroid 1\n",
    "    Returns: \n",
    "        The centroid closest to the data point\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    # SOLN START #\n",
    "    dist1 = np.linalg.norm(data_point - centroid1)\n",
    "    dist2 = np.linalg.norm(data_point - centroid2)\n",
    "    \n",
    "    if dist1 >= dist2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "    # SOLN END #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#YOUR CODE HERE\n",
    "# SOLN START #\n",
    "centroid1 = np.mean(presorted_two_projected[0], axis = 0)\n",
    "centroid2 = np.mean(presorted_two_projected[1], axis=0) \n",
    "# SOLN END #\n",
    "#END YOUR CODE\n",
    "\n",
    "num_of_firings = np.zeros(2)\n",
    "two_projected = two_projected\n",
    "for i in range(0,len(two_projected)):\n",
    "    # YOUR CODE START\n",
    "    # SOLN START #\n",
    "    neuron_number = which_neuron(two_projected[i:], centroid1, centroid2)\n",
    "    # SOLN END\n",
    "    # END YOUR CODE\n",
    "    num_of_firings[neuron_number-1] +=1\n",
    "    \n",
    "print('Neuron 1 Fired ' + str(num_of_firings[0]) + ' times')\n",
    "print('Neuron 2 Fired ' + str(num_of_firings[1]) + ' times')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_centroids(clustered_data, num_of_clusters):\n",
    "    \"\"\" Use scipy.cluster.vq.kmeans to determine centroids of clusters\n",
    "    Parameters:\n",
    "        clustered_data: the data projected onto the new basis\n",
    "        num_of_clusters: the expected number of clusters in the data\n",
    "    Returns: \n",
    "        The centroids of the clusters\n",
    "    Hint 1: make sure to first 'whiten' the data (refer to docs)\n",
    "    \"\"\"\n",
    "    \n",
    "    return scipy.cluster.vq.kmeans(clustered_data, num_of_clusters)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Determine the centroids in the 2-neuron data\n",
    "\n",
    "centroid_list = find_centroids(two_projected, 2)\n",
    "\n",
    "# Print the centroid locations\n",
    "centroid1 = centroid_list[0]\n",
    "centroid2 = centroid_list[1]\n",
    "\n",
    "print('The first centroid is at: ' + str(centroid1))\n",
    "print('The second centroid is at: ' + str(centroid2))\n",
    "\n",
    "# Determine how many times neuron1 and neuron2 fired in the two_classifed data\n",
    "\n",
    "num_of_firings = np.zeros(2)\n",
    "\n",
    "for i in range(0,len(two_projected)):\n",
    "    # YOUR CODE START\n",
    "    # SOLN START #\n",
    "    neuron_number = which_neuron(two_projected[i:], centroid1, centroid2)\n",
    "    # SOLN END\n",
    "    # END YOUR CODE\n",
    "    num_of_firings[neuron_number-1] +=1  \n",
    "    \n",
    "# Print the results\n",
    "print('Neuron 1 Fired ' + str(num_of_firings[0]) + ' times')\n",
    "print('Neuron 2 Fired ' + str(num_of_firings[1]) + ' times')\n",
    "\n",
    "print('Remember, the order of the two clusters has no meaning. Their centroids are what define them.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
